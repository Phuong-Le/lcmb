# lcmb: Output

## Introduction

The directories listed below will be created in the results directory after the pipeline has finished. All paths are relative to the top-level results directory.


## Pipeline output overview

The pipeline is built using [Nextflow](https://www.nextflow.io/) and processes data using the following steps:

- [conpair_out](#conpair) - Conpair for checking contamination
- [filter_snp_out](#filter_snp) - Filtering SNVs
- [filter_indel_out](#filter_indel) - Filtering INDELs
- [phylogenetics_snp_out](#phylogenetics_snp) - phylogenetic analysis for SNVs
- [phylogenetics_indel_out](#phylogenetics_indel) - phylogenetic analysis for INDELs
- [Pipeline information](#pipeline-information) - Report metrics generated during the workflow execution

### Conpair

<details markdown="1">
<summary>Output files</summary>

- `conpair_out/`
  - `pileup/`
    - `sample_id.pileup`: gatk pileup file for the samples
    - `match_normal_id.pileup`: gatk pileup file for the match normal samples
  - `concordance.txt`: concordance score for all pairs of samples - match normal (if `with_match_normal==true`) and all sample pairs (if `with_match_normal==false`)
  - `contamination.txt`: contamination scores for all samples and their match normal (if applicable)
  - `conpair_filter.log`: log file containing information on which samples are filtered out and why
  - `sample_paths_contamination_filtered.tsv`: same format as input samplesheet but with all suspected problematic samples filtered out

### Filter SNVs

<details markdown="1">
<summary>Output files</summary>

- `filter_snp_out/`
  - `pdid/`
    - `*.hairpin.vcf.gz`: hairpin annotated vcf file
    - `*.hairpin.filter.vcf.gz`: vcf file with criteria defined by vcfilter.config file filtered out
    - `*.hairpin.filter.vcf.gz`: tabix index file for above filtered vcf
    - `*_snp_vaf.tsv`: VAF for all samples
    - `germline_ids.txt`: germline variants (this file is only generated if `with_match_normal==false`)
    - `somatic_ids.txt`: somatic variants (this file is only generated if `with_match_normal==false`)
    - `NR_bbinom_filtered.txt`: NR file (number of reads at variants) for all samples
    - `NV_bbinom_filtered.txt`: NV file (reads supporting variants) for all samples
    - `somatic_artefacts_filtered.bed`: loci that pass the germline exact test (if applicable) and the betabinomial test
    - `somatic_ids_rho.txt`: rho value for all variants and whether the variants are filtered out by the betabinomial test
    - `genotype_bin.txt`: binary genotype file for all variants (used for the downstream phylogenetic subworkflow)
    - `*.hairpin.filter.bbinom.vcf`: vcf file that has been filtered out by the beta-binomial test for artefacts
  - `sample_mutmat/`
    - `output/`
      - `SBS/`
        - `sample_mutmat.SBS*.all`: mutation matrices generated by sigprofiler matrix generator
    - `plots/`
      - `SBS/`
        - `*.pdf`: mutation spectra for the samples generated by sigprofiler plotting
      - `pkl/`
        - `*.pkl`: pickle file generated by sigprofiler plotting

### Filter INDELs

<details markdown="1">
<summary>Output files</summary>

- `filter_indel_out/`
  - `pdid/`
    - `*.filter.vcf.gz`: vcf file with criteria defined by vcfilter.config file filtered out
    - `*.filter.vcf.gz`: tabix index file for above filtered vcf
    - `*_indel_vaf.tsv`: VAF for all samples
    - `germline_ids.txt`: germline variants (this file is only generated if `with_match_normal==false`)
    - `somatic_ids.txt`: somatic variants (this file is only generated if `with_match_normal==false`)
    - `NR_bbinom_filtered.txt`: NR file (number of reads at variants) for all samples
    - `NV_bbinom_filtered.txt`: NV file (reads supporting variants) for all samples
    - `somatic_artefacts_filtered.bed`: loci that pass the germline exact test (if applicable) and the betabinomial test
    - `somatic_ids_rho.txt`: rho value for all variants and whether the variants are filtered out by the betabinomial test
    - `genotype_bin.txt`: binary genotype file for all variants (used for the downstream phylogenetic subworkflow)
    - `*.filter.bbinom.vcf`: vcf file that has been filtered out by the beta-binomial test for artefacts
  - `sample_mutmat/`
      - `output/`
        - `SBS/`
          - `sample_mutmat.SBS*.all`: mutation matrices generated by sigprofiler matrix generator
      - `plots/`
        - `SBS/`
          - `*.pdf`: mutation spectra for the samples generated by sigprofiler plotting
        - `pkl/`
          - `*.pkl`: pickle file generated by sigprofiler plotting

### Phylogenetics

<details markdown="1">
<summary>Output files</summary>

- `phylogenetics*_out/`
  - `pdid/`
    - `pdid.fasta`: fasta file for donor ID (generated using `genotype_bin`)
    - `pdid.fasta.log`: log file by MPBoot
    - `pdid.fasta.treefile`: tree topology by MPBoot
    - `pdid.muts_assigned_to_tree.txt`: tree with mutations assigned to its branches/nodes by treemut
    - `pdid.tree_with_branch_length.tree`: tree with adjusted branchlength by treemut
    - `pdid.tree_with_branch_length.pdf`: plotting tree with adjust branchlength by treemut
    - `matrix_by_branch/`: directory containing matrices generated by matrix_generator for each branch on the tree
  - `combined_matrices_by_branches/`
      - `combined_mutmat.SBS*.all`: mutation matrices for all the branches generated by sigprofiler matrix generator
      - `plots/`
        - `SBS/`
          - `*.pdf`: mutation spectra for the branches generated by sigprofiler plotting
        - `pkl/`
          - `*.pkl`: pickle file generated by sigprofiler plotting

### Pipeline information

<details markdown="1">
<summary>Output files</summary>

- `pipeline_info/`
  - Reports generated by Nextflow: `execution_report.html`, `execution_timeline.html`, `execution_trace.txt` and `pipeline_dag.dot`/`pipeline_dag.svg`.
  - Reports generated by the pipeline: `pipeline_report.html`, `pipeline_report.txt` and `software_versions.yml`. The `pipeline_report*` files will only be present if the `--email` / `--email_on_fail` parameter's are used when running the pipeline.
  - Reformatted samplesheet files used as input to the pipeline: `samplesheet.valid.csv`.
  - Parameters used by the pipeline run: `params.json`.

</details>

[Nextflow](https://www.nextflow.io/docs/latest/tracing.html) provides excellent functionality for generating various reports relevant to the running and execution of the pipeline. This will allow you to troubleshoot errors with the running of the pipeline, and also provide you with other information such as launch commands, run times and resource usage.
